package org.firstinspires.ftc.teamcode.vision;

import android.graphics.Bitmap;

import com.acmerobotics.dashboard.FtcDashboard;
import com.acmerobotics.dashboard.telemetry.TelemetryPacket;
import com.qualcomm.robotcore.hardware.HardwareMap;
import com.vuforia.Image;
import com.vuforia.PIXEL_FORMAT;
import com.vuforia.Vuforia;

import org.firstinspires.ftc.robotcore.external.ClassFactory;
import org.firstinspires.ftc.robotcore.external.Telemetry;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaLocalizer;
import org.firstinspires.ftc.teamcode.RC;
import org.firstinspires.ftc.teamcode.statemachine.MineralStateProvider;
import org.firstinspires.ftc.teamcode.util.BlobStats;
import org.firstinspires.ftc.teamcode.util.VisionUtils;
import org.opencv.android.Utils;
import org.opencv.core.*;
import org.opencv.features2d.Features2d;
import org.opencv.features2d.SimpleBlobDetector;
import org.opencv.imgproc.*;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.concurrent.BlockingQueue;

import static org.firstinspires.ftc.teamcode.vision.Config.*;

/**
 * GripPipeline class.
 *
 * <p>An OpenCV pipeline generated by GRIP.
 *
 * @author GRIP
 */
public class TowerHeightPipeline implements SkystoneVisionProvider {
    //vuforia
    private VuforiaLocalizer vuforia;
    private BlockingQueue<VuforiaLocalizer.CloseableFrame> q;
    VuforiaLocalizer.CloseableFrame frame;

    //Statistics
    public List<BlobStats> blobs = new ArrayList<BlobStats>();
    public List<MatOfPoint> contours = new ArrayList<MatOfPoint>();
    public double aspectRatio;
    public SkystoneTargetInfo target;

    //pivs
    private boolean enableDashboard;
    private int state = -1;
    private Mat mat, overlay;
    private boolean isStackingFat = false;

    //debugging
    public Telemetry telemetry;
    public FtcDashboard dashboard;

    //tuned constants
    //aspect ratios for if the stones are facing the camera length-wise
    public static final double[]  ASPECT_RATIOS  = {0.3325, 0.8775, 1.2575, 1.6375, 2.0425, 2.4, 2.7325};
    public static double BLUR_RADIUS = 9.8198;
    public static double[][] HSV_THRESHOLD_PARAMETERS = {
            {15.0, 112.0},
            {200.0, 255.0},
            {30.0, 255.0}
    };

    private void initVuforia(HardwareMap hardwareMap, Viewpoint viewpoint) {
        VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters();
        parameters.vuforiaLicenseKey = RC.VUFORIA_LICENSE_KEY;
        if (viewpoint == Viewpoint.BACK)
            parameters.cameraDirection = VuforiaLocalizer.CameraDirection.BACK;
        else if (viewpoint == Viewpoint.WEBCAM)
            parameters.cameraName = hardwareMap.get(WebcamName.class, "Webcam 1");
        else
            parameters.cameraDirection = VuforiaLocalizer.CameraDirection.FRONT;
        vuforia = ClassFactory.getInstance().createVuforia(parameters);
        Vuforia.setFrameFormat(PIXEL_FORMAT.RGB565, true);
        vuforia.setFrameQueueCapacity(1);
    }

    @Override
    public void initializeVision(HardwareMap hardwareMap, Telemetry telemetry, boolean enableDashboard, Viewpoint viewpoint, boolean isStackingFat) {
        initVuforia(hardwareMap, viewpoint);
        q = vuforia.getFrameQueue();
        state = 0;
        target = new SkystoneTargetInfo();
        this.telemetry = telemetry;
        this.enableDashboard = enableDashboard;
        this.isStackingFat = isStackingFat;
        if (enableDashboard)
            dashboard = FtcDashboard.getInstance();
    }

    @Override
    public void shutdownVision() {
    }

    @Override
    public void reset() {
        state = 0;
    }

    @Override
    public SkystoneTargetInfo detectSkystone() {
        switch (state) {
            case 0:
                if (q.isEmpty()) {
                    target.confidence = 0;
                    target.finished = false;
                    return target;
                }

                VuforiaLocalizer.CloseableFrame frame;
                try {
                    frame = q.take();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                }
                Image img = VisionUtils.getImageFromFrame(frame, PIXEL_FORMAT.RGB565);
                Bitmap bm = Bitmap.createBitmap(img.getWidth(), img.getHeight(), Bitmap.Config.RGB_565);
                bm.copyPixelsFromBuffer(img.getPixels());
                mat = VisionUtils.bitmapToMat(bm, CvType.CV_8UC3);
                overlay = VisionUtils.bitmapToMat(bm, CvType.CV_8UC3);
                break;
            case 1:
                blur(mat, BLUR_RADIUS, overlay);
                hsvThreshold(overlay, HSV_THRESHOLD_PARAMETERS, overlay);
                break;
            case 2:
                List<MatOfPoint> contours = new ArrayList<>();
                Imgproc.findContours(overlay, contours, new Mat(), Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

                // Find max contour area
                double maxArea = 0;
                Iterator<MatOfPoint> each = contours.iterator();
                while (each.hasNext()) {
                    MatOfPoint wrapper = each.next();
                    double area = Imgproc.contourArea(wrapper);
                    if (area > maxArea)
                        maxArea = area;
                }

                // Filter contours by area and resize to fit the original image size
                this.contours.clear();
                each = contours.iterator();
                while (each.hasNext()) {
                    MatOfPoint contour = each.next();
                    if (Imgproc.contourArea(contour) > 0.1 * maxArea) {
                        Core.multiply(contour, new Scalar(4, 4), contour);
                        this.contours.add(contour);
                        Moments p = Imgproc.moments(contour, false);
                        int x = (int) (p.get_m10() / p.get_m00());
                        int y = (int) (p.get_m01() / p.get_m00());
                        double area = Imgproc.contourArea(contour);
                        org.opencv.core.Rect blobBox = Imgproc.boundingRect(contour);
                        BlobStats blob = new BlobStats(p, x, y, blobBox.width, blobBox.height, area);
                        blobs.add(blob);
                        Imgproc.circle(overlay, new Point(x, y), 5, new Scalar(0, 255, 0, 255), 5);
                    }
                    Imgproc.drawContours(overlay, contours, -1, new Scalar(0, 255, 0, 255), 3);
                }
                break;
            case 3:
                if (!enableDashboard)
                    break;
                Bitmap overlayBitmap = Bitmap.createBitmap(overlay.width(), overlay.height(), Bitmap.Config.RGB_565);
                Utils.matToBitmap(overlay, overlayBitmap);
                dashboard.sendImage(overlayBitmap);
                overlay.release();
                break;
            case 4:
                BlobStats largestBlob = null;
                for (BlobStats blobStats : blobs) {
                    if (largestBlob == null)
                        largestBlob = blobStats;
                    else if (blobStats.area > largestBlob.area)
                        largestBlob = blobStats;
                }

                if (largestBlob == null) {
                    target.finished = false;
                    return target;
                }

                target.centroidX = largestBlob.x;
                target.centroidY = largestBlob.y;
                target.width = largestBlob.width;
                target.height = largestBlob.height;
                target.aspectRatio = (double) largestBlob.height / largestBlob.width;

                if(isStackingFat ? aspectRatio < ASPECT_RATIOS[0] : aspectRatio < (ASPECT_RATIOS[0] * 2))
                    target.setStackHeight(0);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[1] : aspectRatio < (ASPECT_RATIOS[1] * 2))
                    target.setStackHeight(1);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[2] : aspectRatio < (ASPECT_RATIOS[2] * 2))
                    target.setStackHeight(2);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[3] : aspectRatio < (ASPECT_RATIOS[3] * 2))
                    target.setStackHeight(3);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[4] : aspectRatio < (ASPECT_RATIOS[4] * 2))
                    target.setStackHeight(4);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[5] : aspectRatio < (ASPECT_RATIOS[5] * 2))
                    target.setStackHeight(5);
                else if(isStackingFat ? aspectRatio < ASPECT_RATIOS[6] : aspectRatio < (ASPECT_RATIOS[6] * 2))
                    target.setStackHeight(6);
                else
                    target.setStackHeight(7);

                target.confidence = 1;
                return target;
            default:
                target.confidence = 0;
                target.finished = false;
                return target;
        }
        state++;
        target.confidence = 0;
        target.finished = false;
        return target;
    }

    private void blur(Mat input, double doubleRadius, Mat output) {
        int radius = (int)(doubleRadius + 0.5);
        int kernelSize;
        kernelSize = 6 * radius + 1;
        Imgproc.GaussianBlur(input,output, new Size(kernelSize, kernelSize), radius);
    }

    private void hsvThreshold(Mat input, double[][] threshold, Mat out) {
        Imgproc.cvtColor(input, out, Imgproc.COLOR_BGR2HSV);
        Core.inRange(out,
                new Scalar(threshold[0][0], threshold[1][0], threshold[2][0]),
                new Scalar(threshold[0][1], threshold[1][1], threshold[2][1]),
                out);
    }

    private Mat crop(Mat image, Point topLeftCorner, Point bottomRightCorner) {
        Rect cropRect = new Rect(topLeftCorner, bottomRightCorner);
        return new Mat(image, cropRect);
    }
}
